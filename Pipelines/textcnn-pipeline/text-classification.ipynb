{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification by convolutional neural network\n",
    "\n",
    "This sample pipeline contains some modules that implement with Text CNN for sentiment classification scenarios.\n",
    "\n",
    "You will learn how to:\n",
    "* Register modules from local code using module SDK.\n",
    "* Build pipeline with registered modules and AzureML built-in modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Install azure cli with azure-cli-ml extension following the [instructions here](setup-environment.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup workspace\n",
    "\n",
    "Login to azure with cli and set the default workspace using `az ml folder attach` command.\n",
    "\n",
    "After this operation, the workspace could be retrived with the `Workspace.from_config()` for SDK usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Update the following information with your environment\n",
    "\n",
    "SUBSCRIPTION_ID = '<your subscription ID>'\n",
    "WORKSPACE_NAME = '<your workspace name>'\n",
    "RESOURCE_GROUP_NAME = '<your resource group>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login -o none \n",
    "!az account set -s $SUBSCRIPTION_ID \n",
    "!az ml folder attach -w $WORKSPACE_NAME -g $RESOURCE_GROUP_NAME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve or create an Azure Machine Learning compute target\n",
    "Azure Machine Learning Compute is a service for provisioning and managing clusters of Azure virtual machines for running machine learning workloads. Create a new Azure Machine Learning Compute in the current workspace, if it doesn't already exist. We will then run the pipeline on this compute target.\n",
    "\n",
    "If we could not find the compute with the given name, then we will create a new compute here. This process is broken down into the following steps:\n",
    "\n",
    "1. Create the configuration\n",
    "2. Create the Azure Machine Learning compute\n",
    "\n",
    "**This process will take a few minutes and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training dataset\n",
    "\n",
    "Download [IMDB Dataset of 50k Movie Reviews](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) and then register it \"From Local\" via Azure Machine Learning portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from azureml.core import Dataset\n",
    "\n",
    "training_data_name = 'IMDB_Dataset_Samples'\n",
    "path = 'assets/text-classification/data/'\n",
    "\n",
    "if training_data_name not in ws.datasets:\n",
    "    print('Registering a training dataset ...')\n",
    "\n",
    "    # Upload path to datastore\n",
    "    m = hashlib.sha256()\n",
    "    m.update(path.encode())\n",
    "    ds_path = m.hexdigest()\n",
    "\n",
    "    datastore = ws.get_default_datastore()\n",
    "    path_on_datastore = folder_on_datastore = f'/data/{ds_path}'\n",
    "    datastore.upload(path, target_path=folder_on_datastore)\n",
    "\n",
    "    # Create a FileDataset\n",
    "    datastore_paths = [(datastore, path_on_datastore + '/**')]\n",
    "    train_data = Dataset.File.from_files(datastore_paths)\n",
    "    print(f\"Registering dataset for path {path}\")\n",
    "    train_data.register(workspace=ws,\n",
    "                        name=training_data_name,\n",
    "                        description='Training data (just for illustrative purpose)')\n",
    "    print('Registerd')\n",
    "else:\n",
    "    train_data = ws.datasets[training_data_name]\n",
    "    print('Training dataset found in workspace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or register TextCNN modules\n",
    "\n",
    "Load TextCNN related modules. If module not found, register with module SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.wrapper import Module\n",
    "\n",
    "try:\n",
    "    textcnn_train_module_func = Module.load(ws, namespace='microsoft.com/azureml/samples', name='TextCNN Train Model')\n",
    "    textcnn_score_module_func = Module.load(ws, namespace='microsoft.com/azureml/samples', name='TextCNN Score Model')\n",
    "    textcnn_preprocess_module_func = Module.load(ws, namespace='microsoft.com/azureml/samples', name='TextCNN Word to Id')\n",
    "    print(\"Load modules successfully.\")\n",
    "except:\n",
    "    print(\"Registering modules ...\")\n",
    "    textcnn_train_module_func = Module.register(ws, 'modules/textcnn-train/train.yaml')\n",
    "    textcnn_score_module_func = Module.register(ws, 'modules/textcnn-score/score.yaml')\n",
    "    textcnn_preprocess_module_func = Module.register(ws, 'modules/textcnn-preprocess/preprocess.yaml')\n",
    "    print(\"Modules registered and loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load built-in modules\n",
    "\n",
    "There are some built-in modules in AzureML Designer. They are located in 'azureml' namespace.\n",
    "\n",
    "Use the following code to load built-in modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_module_func = Module.load(ws, namespace='azureml', name='Split Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline and run\n",
    "\n",
    "Create a pipeline using the modules, and submit experiment to AzureML using module SDK.\n",
    "\n",
    "Here is a [preview of the pipeline](assets/text-classification/pipeline.png).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.wrapper import dsl\n",
    "\n",
    "# Create the pipeline\n",
    "@dsl.pipeline(name='textcnn_train_pipeline_with_builtin_modules',\n",
    "              description='TextCNN training pipeline with IMDB_Dataset_Samples.csv dataset',\n",
    "              default_compute_target=aml_compute_target)\n",
    "def sample_pipeline():\n",
    "    split_data_module = split_data_module_func(\n",
    "        dataset=train_data, \n",
    "        splitting_mode='Split Rows',\n",
    "        fraction_of_rows_in_the_first_output_dataset = 0.8,\n",
    "        randomized_split = True\n",
    "    )\n",
    "    \n",
    "    textcnn_train_module = textcnn_train_module_func(\n",
    "        train_data_file=split_data_module.outputs.results_dataset1, \n",
    "        validation_data_file=split_data_module.outputs.results_dataset2,\n",
    "        label_column_name='sentiment',\n",
    "        true_label_value='positive',\n",
    "        text_column_name='review'\n",
    "    )\n",
    "    \n",
    "    textcnn_preprocess_module = textcnn_preprocess_module_func(\n",
    "        input_vocab=textcnn_train_module.outputs.vocab, \n",
    "        input_text=split_data_module.outputs.results_dataset2,\n",
    "        text_column_name='review'\n",
    "    )\n",
    "\n",
    "    textcnn_score_module = textcnn_score_module_func(\n",
    "        trained_model=textcnn_train_module.outputs.trained_model, \n",
    "        predict_data=textcnn_preprocess_module.outputs.processed_data\n",
    "    )\n",
    "\n",
    "pipeline = sample_pipeline()\n",
    "pipeline.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submit pipeline\n",
    "run = pipeline.submit(\n",
    "    experiment_name='textcnn_train'\n",
    ")\n",
    "\n",
    "# Show details of the run\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait until the run completes\n",
    "run.wait_for_completion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}